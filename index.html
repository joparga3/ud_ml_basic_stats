<!DOCTYPE html>

<html xmlns="http://www.w3.org/1999/xhtml">

<head>

<meta charset="utf-8" />
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="generator" content="pandoc" />


<meta name="author" content="Jose Parreno Garcia" />


<title>Basic Stats</title>

<script src="site_libs/jquery-1.11.3/jquery.min.js"></script>
<meta name="viewport" content="width=device-width, initial-scale=1" />
<link href="site_libs/bootstrap-3.3.5/css/bootstrap.min.css" rel="stylesheet" />
<script src="site_libs/bootstrap-3.3.5/js/bootstrap.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/html5shiv.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/respond.min.js"></script>
<script src="site_libs/navigation-1.1/tabsets.js"></script>
<link href="site_libs/highlightjs-1.1/default.css" rel="stylesheet" />
<script src="site_libs/highlightjs-1.1/highlight.js"></script>

<style type="text/css">code{white-space: pre;}</style>
<style type="text/css">
  pre:not([class]) {
    background-color: white;
  }
</style>
<script type="text/javascript">
if (window.hljs && document.readyState && document.readyState === "complete") {
   window.setTimeout(function() {
      hljs.initHighlighting();
   }, 0);
}
</script>



<style type="text/css">
h1 {
  font-size: 34px;
}
h1.title {
  font-size: 38px;
}
h2 {
  font-size: 30px;
}
h3 {
  font-size: 24px;
}
h4 {
  font-size: 18px;
}
h5 {
  font-size: 16px;
}
h6 {
  font-size: 12px;
}
.table th:not([align]) {
  text-align: left;
}
</style>


</head>

<body>

<style type = "text/css">
.main-container {
  max-width: 940px;
  margin-left: auto;
  margin-right: auto;
}
code {
  color: inherit;
  background-color: rgba(0, 0, 0, 0.04);
}
img {
  max-width:100%;
  height: auto;
}
.tabbed-pane {
  padding-top: 12px;
}
button.code-folding-btn:focus {
  outline: none;
}
</style>


<style type="text/css">
/* padding for bootstrap navbar */
body {
  padding-top: 51px;
  padding-bottom: 40px;
}
/* offset scroll position for anchor links (for fixed navbar)  */
.section h1 {
  padding-top: 56px;
  margin-top: -56px;
}

.section h2 {
  padding-top: 56px;
  margin-top: -56px;
}
.section h3 {
  padding-top: 56px;
  margin-top: -56px;
}
.section h4 {
  padding-top: 56px;
  margin-top: -56px;
}
.section h5 {
  padding-top: 56px;
  margin-top: -56px;
}
.section h6 {
  padding-top: 56px;
  margin-top: -56px;
}
</style>

<script>
// manage active state of menu based on current page
$(document).ready(function () {
  // active menu anchor
  href = window.location.pathname
  href = href.substr(href.lastIndexOf('/') + 1)
  if (href === "")
    href = "index.html";
  var menuAnchor = $('a[href="' + href + '"]');

  // mark it active
  menuAnchor.parent().addClass('active');

  // if it's got a parent navbar menu mark it active as well
  menuAnchor.closest('li.dropdown').addClass('active');
});
</script>


<div class="container-fluid main-container">

<!-- tabsets -->
<script>
$(document).ready(function () {
  window.buildTabsets("TOC");
});
</script>

<!-- code folding -->






<div class="navbar navbar-default  navbar-fixed-top" role="navigation">
  <div class="container">
    <div class="navbar-header">
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar">
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <a class="navbar-brand" href="index.html">Basic Stats</a>
    </div>
    <div id="navbar" class="navbar-collapse collapse">
      <ul class="nav navbar-nav">
        <li>
  <a href="index.html">Basic Stats</a>
</li>
      </ul>
      <ul class="nav navbar-nav navbar-right">
        
      </ul>
    </div><!--/.nav-collapse -->
  </div><!--/.container -->
</div><!--/.navbar -->

<div class="fluid-row" id="header">



<h1 class="title toc-ignore">Basic Stats</h1>
<h4 class="author"><em>Jose Parreno Garcia</em></h4>
<h4 class="date"><em>February 2018</em></h4>

</div>

<div id="TOC">
<ul>
<li><a href="#understanding-data-sampling-in-r"><span class="toc-section-number">1</span> Understanding data sampling in R</a></li>
<li><a href="#operating-a-probability-distribution-in-r"><span class="toc-section-number">2</span> Operating a probability distribution in R</a><ul>
<li><a href="#testing-normality-of-the-data-with-a-shapiro-test"><span class="toc-section-number">2.1</span> Testing normality of the data with a shapiro test</a></li>
</ul></li>
<li><a href="#working-with-univariate-descriptive-statistics-in-r"><span class="toc-section-number">3</span> Working with univariate descriptive statistics in R</a><ul>
<li><a href="#basic-stats"><span class="toc-section-number">3.1</span> Basic stats</a></li>
<li><a href="#basic-histogram-and-mode"><span class="toc-section-number">3.2</span> Basic histogram and mode</a></li>
</ul></li>
<li><a href="#performing-correlations-and-multivariate-analysis"><span class="toc-section-number">4</span> Performing correlations and multivariate analysis</a></li>
<li><a href="#operating-linear-regression-and-multivariate-analysis"><span class="toc-section-number">5</span> Operating linear regression and multivariate analysis</a></li>
<li><a href="#conducting-an-statistical-tests"><span class="toc-section-number">6</span> Conducting an statistical tests</a><ul>
<li><a href="#binomial-test"><span class="toc-section-number">6.1</span> Binomial test</a></li>
<li><a href="#student-t-test"><span class="toc-section-number">6.2</span> Student t-test</a><ul>
<li><a href="#sample-t-test"><span class="toc-section-number">6.2.1</span> 1-sample t-test</a></li>
<li><a href="#sample-t-test-1"><span class="toc-section-number">6.2.2</span> 2-sample t-test</a></li>
</ul></li>
<li><a href="#kolmogorov-smirnov-test"><span class="toc-section-number">6.3</span> Kolmogorov-Smirnov Test</a><ul>
<li><a href="#sample-ks-test"><span class="toc-section-number">6.3.1</span> 1-sample KS test</a></li>
<li><a href="#sample-ks-test-1"><span class="toc-section-number">6.3.2</span> 2-sample KS test</a></li>
</ul></li>
<li><a href="#wilcoxon-rank-sum-and-signed-rank-test"><span class="toc-section-number">6.4</span> Wilcoxon Rank Sum and Signed Rank Test</a></li>
<li><a href="#pearson-chi-squared-test"><span class="toc-section-number">6.5</span> Pearson chi-squared test</a></li>
<li><a href="#anova"><span class="toc-section-number">6.6</span> ANOVA</a><ul>
<li><a href="#way-anova"><span class="toc-section-number">6.6.1</span> 1-way ANOVA</a></li>
<li><a href="#way-anova-1"><span class="toc-section-number">6.6.2</span> 2-way ANOVA</a></li>
</ul></li>
</ul></li>
</ul>
</div>

<style>
body {
text-align: justify}

</style>
<p><br></p>
<pre class="r"><code>library(knitr)</code></pre>
<p><br></p>
<p>We will look at:</p>
<ul>
<li>Understanding data sampling in R</li>
<li>Operating a probability distribution in R</li>
<li>Working with univariate descriptive statistics in R</li>
<li>Performing correlations and multivariate analysis</li>
<li>Operating linear regression and multivariate analysis</li>
<li>Conducting an statistical tests</li>
</ul>
<div id="understanding-data-sampling-in-r" class="section level1">
<h1><span class="header-section-number">1</span> Understanding data sampling in R</h1>
<p>There are several reasons why sampling are used:</p>
<ul>
<li>When using machine learning or predictive modelling, we can sample our data to create different datasets which we use to train/test/validate</li>
<li>When you have a massive dataset and little computational power, you want to extract samples of the data that are representative of the wider population to model on those.</li>
</ul>
<pre class="r"><code># Randomnly sample a vector
sample(1:10)</code></pre>
<pre><code>##  [1]  6  9 10  1  7  5  8  2  3  4</code></pre>
<pre class="r"><code># Randomnly sample a vector and return X number of elements
sample(1:10, size = 5)</code></pre>
<pre><code>## [1]  9  1  2 10  7</code></pre>
<pre class="r"><code># Randomnly sample a vector with Bernouilli trials - ie - being able to repeat elements.
sample(c(0,1), 10, replace = TRUE)</code></pre>
<pre><code>##  [1] 0 0 1 0 1 1 0 1 1 1</code></pre>
<pre class="r"><code># Randomnly sample a vector that can only return integers
sample.int(20, 12)</code></pre>
<pre><code>##  [1] 10  5  1  2 19  6  3 11 15 17 14 16</code></pre>
<p><br></p>
</div>
<div id="operating-a-probability-distribution-in-r" class="section level1">
<h1><span class="header-section-number">2</span> Operating a probability distribution in R</h1>
<p>Remember the second point above?</p>
<ul>
<li>When you have a massive dataset and little computational power, you want to extract samples of the data that are representative of the wider population to model on those.</li>
</ul>
<p><img src="images/1.PNG" width="556" /></p>
<p>Creating different distributions:</p>
<pre class="r"><code>library(stats)

# Normal distribution -&gt; returning &quot;height&quot; of the curve at point 0
dnorm(0)</code></pre>
<pre><code>## [1] 0.3989423</code></pre>
<pre class="r"><code># Idem as above, but having a mean and standard deviation
dnorm(0,mean=3,sd=5)</code></pre>
<pre><code>## [1] 0.06664492</code></pre>
<pre class="r"><code># Plotting a normal distribution
curve(dnorm,-3,3)</code></pre>
<p><img src="index_files/figure-html/unnamed-chunk-29-1.png" /><!-- --></p>
<pre class="r"><code># Normal distribution -&gt; returning the area under/left a given value
pnorm(1.5)</code></pre>
<pre><code>## [1] 0.9331928</code></pre>
<pre class="r"><code># Normal distribution -&gt; returning the area above/right a given value
pnorm(1.5, lower.tail=FALSE)</code></pre>
<pre><code>## [1] 0.0668072</code></pre>
<pre class="r"><code># Plotting
curve(pnorm(x), -3,3)</code></pre>
<p><img src="index_files/figure-html/unnamed-chunk-29-2.png" /><!-- --></p>
<pre class="r"><code># Normal distribution -&gt; quantiles
qnorm(0.5)</code></pre>
<pre><code>## [1] 0</code></pre>
<pre class="r"><code># Generate random numbers from a normal distribution
set.seed(50)
x = rnorm(100,mean=3,sd=5)
hist(x)</code></pre>
<p><img src="index_files/figure-html/unnamed-chunk-29-3.png" /><!-- --></p>
<pre class="r"><code># Generate random numbers from a uniform distribution
set.seed(50)
y = runif(100,0,5)
hist(y)</code></pre>
<p><img src="index_files/figure-html/unnamed-chunk-29-4.png" /><!-- --></p>
<div id="testing-normality-of-the-data-with-a-shapiro-test" class="section level2">
<h2><span class="header-section-number">2.1</span> Testing normality of the data with a shapiro test</h2>
<pre class="r"><code># p-value is above 0.05 -&gt; normal distribution
shapiro.test(x)</code></pre>
<pre><code>## 
##  Shapiro-Wilk normality test
## 
## data:  x
## W = 0.99381, p-value = 0.9318</code></pre>
<pre class="r"><code># p-value is below 0.05 -&gt; not a normal distribution
shapiro.test(y)</code></pre>
<pre><code>## 
##  Shapiro-Wilk normality test
## 
## data:  y
## W = 0.95633, p-value = 0.002221</code></pre>
</div>
</div>
<div id="working-with-univariate-descriptive-statistics-in-r" class="section level1">
<h1><span class="header-section-number">3</span> Working with univariate descriptive statistics in R</h1>
<p>We say univariate descriptive statistics because we are generating calculating for a single variable.</p>
<div id="basic-stats" class="section level2">
<h2><span class="header-section-number">3.1</span> Basic stats</h2>
<pre class="r"><code>data(mtcars)

range(mtcars$mpg)</code></pre>
<pre><code>## [1] 10.4 33.9</code></pre>
<pre class="r"><code>length(mtcars$mpg)</code></pre>
<pre><code>## [1] 32</code></pre>
<pre class="r"><code>mean(mtcars$mpg)</code></pre>
<pre><code>## [1] 20.09062</code></pre>
<pre class="r"><code>median(mtcars$mpg)</code></pre>
<pre><code>## [1] 19.2</code></pre>
<pre class="r"><code>sd(mtcars$mpg)</code></pre>
<pre><code>## [1] 6.026948</code></pre>
<pre class="r"><code>var(mtcars$mpg)</code></pre>
<pre><code>## [1] 36.3241</code></pre>
<pre class="r"><code>sd(mtcars$mpg) ^ 2</code></pre>
<pre><code>## [1] 36.3241</code></pre>
<pre class="r"><code>IQR(mtcars$mpg)</code></pre>
<pre><code>## [1] 7.375</code></pre>
<pre class="r"><code>quantile(mtcars$mpg,0.67)</code></pre>
<pre><code>##  67% 
## 21.4</code></pre>
<pre class="r"><code>max(mtcars$mpg)</code></pre>
<pre><code>## [1] 33.9</code></pre>
<pre class="r"><code>min(mtcars$mpg)</code></pre>
<pre><code>## [1] 10.4</code></pre>
<pre class="r"><code>cummax(mtcars$mpg)</code></pre>
<pre><code>##  [1] 21.0 21.0 22.8 22.8 22.8 22.8 22.8 24.4 24.4 24.4 24.4 24.4 24.4 24.4 24.4 24.4 24.4 32.4 32.4 33.9 33.9 33.9 33.9 33.9 33.9 33.9 33.9 33.9 33.9 33.9 33.9 33.9</code></pre>
<pre class="r"><code>cummin(mtcars$mpg)</code></pre>
<pre><code>##  [1] 21.0 21.0 21.0 21.0 18.7 18.1 14.3 14.3 14.3 14.3 14.3 14.3 14.3 14.3 10.4 10.4 10.4 10.4 10.4 10.4 10.4 10.4 10.4 10.4 10.4 10.4 10.4 10.4 10.4 10.4 10.4 10.4</code></pre>
<pre class="r"><code>summary(mtcars)</code></pre>
<pre><code>##       mpg             cyl             disp             hp             drat             wt             qsec             vs               am              gear            carb      
##  Min.   :10.40   Min.   :4.000   Min.   : 71.1   Min.   : 52.0   Min.   :2.760   Min.   :1.513   Min.   :14.50   Min.   :0.0000   Min.   :0.0000   Min.   :3.000   Min.   :1.000  
##  1st Qu.:15.43   1st Qu.:4.000   1st Qu.:120.8   1st Qu.: 96.5   1st Qu.:3.080   1st Qu.:2.581   1st Qu.:16.89   1st Qu.:0.0000   1st Qu.:0.0000   1st Qu.:3.000   1st Qu.:2.000  
##  Median :19.20   Median :6.000   Median :196.3   Median :123.0   Median :3.695   Median :3.325   Median :17.71   Median :0.0000   Median :0.0000   Median :4.000   Median :2.000  
##  Mean   :20.09   Mean   :6.188   Mean   :230.7   Mean   :146.7   Mean   :3.597   Mean   :3.217   Mean   :17.85   Mean   :0.4375   Mean   :0.4062   Mean   :3.688   Mean   :2.812  
##  3rd Qu.:22.80   3rd Qu.:8.000   3rd Qu.:326.0   3rd Qu.:180.0   3rd Qu.:3.920   3rd Qu.:3.610   3rd Qu.:18.90   3rd Qu.:1.0000   3rd Qu.:1.0000   3rd Qu.:4.000   3rd Qu.:4.000  
##  Max.   :33.90   Max.   :8.000   Max.   :472.0   Max.   :335.0   Max.   :4.930   Max.   :5.424   Max.   :22.90   Max.   :1.0000   Max.   :1.0000   Max.   :5.000   Max.   :8.000</code></pre>
<pre class="r"><code>table(mtcars$cyl)</code></pre>
<pre><code>## 
##  4  6  8 
## 11  7 14</code></pre>
<pre class="r"><code>stem(mtcars$mpg)</code></pre>
<pre><code>## 
##   The decimal point is at the |
## 
##   10 | 44
##   12 | 3
##   14 | 3702258
##   16 | 438
##   18 | 17227
##   20 | 00445
##   22 | 88
##   24 | 4
##   26 | 03
##   28 | 
##   30 | 44
##   32 | 49</code></pre>
</div>
<div id="basic-histogram-and-mode" class="section level2">
<h2><span class="header-section-number">3.2</span> Basic histogram and mode</h2>
<pre class="r"><code>library(ggplot2)

qplot(mtcars$mpg, binwidth=2)</code></pre>
<p><img src="index_files/figure-html/unnamed-chunk-32-1.png" /><!-- --></p>
<pre class="r"><code>mode = function(x) {
   temp = table(x)
   names(temp)[temp == max(temp)]
  }

x = c(1,2,3,3,3,4,4,5,5,5,6)
mode(x)</code></pre>
<pre><code>## [1] &quot;3&quot; &quot;5&quot;</code></pre>
<p><br></p>
</div>
</div>
<div id="performing-correlations-and-multivariate-analysis" class="section level1">
<h1><span class="header-section-number">4</span> Performing correlations and multivariate analysis</h1>
<p><img src="images/2.PNG" width="644" /></p>
<pre class="r"><code># Covariance matrix
cov(mtcars[1:3])</code></pre>
<pre><code>##              mpg        cyl       disp
## mpg    36.324103  -9.172379  -633.0972
## cyl    -9.172379   3.189516   199.6603
## disp -633.097208 199.660282 15360.7998</code></pre>
<pre class="r"><code># Correlation matrix
cor(mtcars[1:3])</code></pre>
<pre><code>##             mpg        cyl       disp
## mpg   1.0000000 -0.8521620 -0.8475514
## cyl  -0.8521620  1.0000000  0.9020329
## disp -0.8475514  0.9020329  1.0000000</code></pre>
<pre class="r"><code># Plotting heatmap
library(reshape2)
qplot(x=Var1, y=Var2, data=melt(cor(mtcars[1:3])), fill=value,
        geom=&quot;tile&quot;)</code></pre>
<p><img src="index_files/figure-html/unnamed-chunk-34-1.png" /><!-- --></p>
<p><br></p>
</div>
<div id="operating-linear-regression-and-multivariate-analysis" class="section level1">
<h1><span class="header-section-number">5</span> Operating linear regression and multivariate analysis</h1>
<pre class="r"><code># Create linear regression
lmfit = lm(mtcars$mpg ~ mtcars$cyl)
lmfit</code></pre>
<pre><code>## 
## Call:
## lm(formula = mtcars$mpg ~ mtcars$cyl)
## 
## Coefficients:
## (Intercept)   mtcars$cyl  
##      37.885       -2.876</code></pre>
<pre class="r"><code># Checking summary of the model
summary(lmfit)</code></pre>
<pre><code>## 
## Call:
## lm(formula = mtcars$mpg ~ mtcars$cyl)
## 
## Residuals:
##     Min      1Q  Median      3Q     Max 
## -4.9814 -2.1185  0.2217  1.0717  7.5186 
## 
## Coefficients:
##             Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept)  37.8846     2.0738   18.27  &lt; 2e-16 ***
## mtcars$cyl   -2.8758     0.3224   -8.92 6.11e-10 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 3.206 on 30 degrees of freedom
## Multiple R-squared:  0.7262, Adjusted R-squared:  0.7171 
## F-statistic: 79.56 on 1 and 30 DF,  p-value: 6.113e-10</code></pre>
<pre class="r"><code># Anova test of the model - analysis of the variance function
anova(lmfit)</code></pre>
<pre><code>## Analysis of Variance Table
## 
## Response: mtcars$mpg
##            Df Sum Sq Mean Sq F value    Pr(&gt;F)    
## mtcars$cyl  1 817.71  817.71  79.561 6.113e-10 ***
## Residuals  30 308.33   10.28                      
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
<pre class="r"><code># Plotting the model
lmfit = lm(mtcars$mpg ~ mtcars$cyl)
plot(mtcars$cyl, mtcars$mpg)
abline(lmfit)</code></pre>
<p><img src="index_files/figure-html/unnamed-chunk-35-1.png" /><!-- --></p>
<p><br></p>
</div>
<div id="conducting-an-statistical-tests" class="section level1">
<h1><span class="header-section-number">6</span> Conducting an statistical tests</h1>
<div id="binomial-test" class="section level2">
<h2><span class="header-section-number">6.1</span> Binomial test</h2>
<p><img src="images/3.PNG" width="347" /><img src="images/4.PNG" width="710" /></p>
<p>Imagine we are in a dice game, and a new player comes in with his own dice. If we expect dices to be fair, then, overall and after many plays, more or less all numbers should have appeared 1/6 of the total times. If the new player always plays to win with number 5, and we have computed he has won 92 times out of 315, we can determine if the dice he was using could be fake.</p>
<pre class="r"><code>binom.test(x=92, n=315, p=1/6)</code></pre>
<pre><code>## 
##  Exact binomial test
## 
## data:  92 and 315
## number of successes = 92, number of trials = 315, p-value = 3.458e-08
## alternative hypothesis: true probability of success is not equal to 0.1666667
## 95 percent confidence interval:
##  0.2424273 0.3456598
## sample estimates:
## probability of success 
##              0.2920635</code></pre>
</div>
<div id="student-t-test" class="section level2">
<h2><span class="header-section-number">6.2</span> Student t-test</h2>
<p><img src="images/5.PNG" width="648" /></p>
<div id="sample-t-test" class="section level3">
<h3><span class="header-section-number">6.2.1</span> 1-sample t-test</h3>
<pre class="r"><code>## ONLY COMPARING MPG

# Visualise attributes against each other - it is clear that the mean of &quot;automobile&quot; is different to the &quot;overall&quot; mean
boxplot(mtcars$mpg, mtcars$mpg[mtcars$am==0], ylab = &quot;mpg&quot;, names=c(&quot;overall&quot;,&quot;automobile&quot;))
abline(h=mean(mtcars$mpg),lwd=2, col=&quot;red&quot;)
abline(h=mean(mtcars$mpg[mtcars$am==0]),lwd=2, col=&quot;blue&quot;)</code></pre>
<p><img src="index_files/figure-html/unnamed-chunk-39-1.png" /><!-- --></p>
<pre class="r"><code># Check this with a T-test
mpg.mu = mean(mtcars$mpg)
mpg_am = mtcars$mpg[mtcars$am == 0]
t.test(mpg_am,mu = mpg.mu)</code></pre>
<pre><code>## 
##  One Sample t-test
## 
## data:  mpg_am
## t = -3.3462, df = 18, p-value = 0.003595
## alternative hypothesis: true mean is not equal to 20.09062
## 95 percent confidence interval:
##  15.29946 18.99528
## sample estimates:
## mean of x 
##  17.14737</code></pre>
</div>
<div id="sample-t-test-1" class="section level3">
<h3><span class="header-section-number">6.2.2</span> 2-sample t-test</h3>
<pre class="r"><code>## COMPARING 2 VARIABLES

# Visualise attributes against each other - it is clear that the mean of &quot;automobile&quot; is different to the &quot;manual&quot; mean
boxplot(mtcars$mpg~mtcars$am,ylab=&#39;mpg&#39;,names=c(&#39;automatic&#39;,&#39;manual&#39;))
abline(h=mean(mtcars$mpg[mtcars$am==0]),lwd=2, col=&quot;blue&quot;)
abline(h=mean(mtcars$mpg[mtcars$am==1]),lwd=2, col=&quot;red&quot;)</code></pre>
<p><img src="index_files/figure-html/unnamed-chunk-40-1.png" /><!-- --></p>
<pre class="r"><code>t.test(mtcars$mpg~mtcars$am)</code></pre>
<pre><code>## 
##  Welch Two Sample t-test
## 
## data:  mtcars$mpg by mtcars$am
## t = -3.7671, df = 18.332, p-value = 0.001374
## alternative hypothesis: true difference in means is not equal to 0
## 95 percent confidence interval:
##  -11.280194  -3.209684
## sample estimates:
## mean in group 0 mean in group 1 
##        17.14737        24.39231</code></pre>
<p><br></p>
</div>
</div>
<div id="kolmogorov-smirnov-test" class="section level2">
<h2><span class="header-section-number">6.3</span> Kolmogorov-Smirnov Test</h2>
<p><img src="images/6.PNG" width="692" /><img src="images/7.PNG" width="681" /></p>
<div id="sample-ks-test" class="section level3">
<h3><span class="header-section-number">6.3.1</span> 1-sample KS test</h3>
<p>Comparing a sample with a reference probability. In the case below, we generate a random distribution X, and check what the KS test decides about it.</p>
<pre class="r"><code># Generate set
x = rnorm(50)

# KS test -&gt; results show that the input is normally distributed as the p-value is bigger than 0.05 and we dont reject the null hypothesis.
ks.test(x,&quot;pnorm&quot;)</code></pre>
<pre><code>## 
##  One-sample Kolmogorov-Smirnov test
## 
## data:  x
## D = 0.076872, p-value = 0.9071
## alternative hypothesis: two-sided</code></pre>
</div>
<div id="sample-ks-test-1" class="section level3">
<h3><span class="header-section-number">6.3.2</span> 2-sample KS test</h3>
<p>Comparing cumulative distribution of 2 samples</p>
<pre class="r"><code># Generate sample data
set.seed(3)
x = runif(n=20, min=0, max=20)
y = runif(n=20, min=0, max=20)

# Checking visually
plot(ecdf(x), do.points = FALSE, verticals=T, xlim=c(0, 20))
lines(ecdf(y), lty=3, do.points = FALSE, verticals=T)</code></pre>
<p><img src="index_files/figure-html/unnamed-chunk-43-1.png" /><!-- --></p>
<pre class="r"><code># KS test -&gt; do both datasets come from the same distribution? Given the p-value is bigger than 0.05, we dont reject the null hypothesis and therefore, both datasets are possibly from the same distribution.
ks.test(x,y)</code></pre>
<pre><code>## 
##  Two-sample Kolmogorov-Smirnov test
## 
## data:  x and y
## D = 0.3, p-value = 0.3356
## alternative hypothesis: two-sided</code></pre>
</div>
</div>
<div id="wilcoxon-rank-sum-and-signed-rank-test" class="section level2">
<h2><span class="header-section-number">6.4</span> Wilcoxon Rank Sum and Signed Rank Test</h2>
<p><img src="images/8.PNG" width="711" /></p>
<pre class="r"><code>boxplot(mtcars$mpg~mtcars$am,ylab=&#39;mpg&#39;,names=c(&#39;automatic&#39;,&#39;manual&#39;))</code></pre>
<p><img src="index_files/figure-html/unnamed-chunk-45-1.png" /><!-- --></p>
<pre class="r"><code># Is the distribution of manual transmission cars the same as the distribution of automatic transmission cars? -&gt; given that p-value is less than 0.05, we reject H0 and conclude that distributions are not the same.
wilcox.test(mpg ~ am, data=mtcars)</code></pre>
<pre><code>## Warning in wilcox.test.default(x = c(21.4, 18.7, 18.1, 14.3, 24.4, 22.8, : cannot compute exact p-value with ties</code></pre>
<pre><code>## 
##  Wilcoxon rank sum test with continuity correction
## 
## data:  mpg by am
## W = 42, p-value = 0.001871
## alternative hypothesis: true location shift is not equal to 0</code></pre>
</div>
<div id="pearson-chi-squared-test" class="section level2">
<h2><span class="header-section-number">6.5</span> Pearson chi-squared test</h2>
<p>Determine whether the distribution of categorical variables of 2 groups differ.</p>
<p><img src="images/9.PNG" width="622" /><img src="images/10.PNG" width="561" /><img src="images/11.PNG" width="388" /><img src="images/12.PNG" width="726" /></p>
<pre class="r"><code>ftable = table(mtcars$am, mtcars$gear)
ftable</code></pre>
<pre><code>##    
##      3  4  5
##   0 15  4  0
##   1  0  8  5</code></pre>
<pre class="r"><code>mosaicplot(ftable, main=&quot;Number of Forward Gears Within
                        Automatic and Manual Cars&quot;, color = TRUE)</code></pre>
<p><img src="index_files/figure-html/unnamed-chunk-47-1.png" /><!-- --></p>
<pre class="r"><code># Given that p-value is less than 0.05, we reject H0, therefore we conclude the distribution of both variables is not the same
chisq.test(ftable)</code></pre>
<pre><code>## Warning in chisq.test(ftable): Chi-squared approximation may be incorrect</code></pre>
<pre><code>## 
##  Pearson&#39;s Chi-squared test
## 
## data:  ftable
## X-squared = 20.945, df = 2, p-value = 2.831e-05</code></pre>
</div>
<div id="anova" class="section level2">
<h2><span class="header-section-number">6.6</span> ANOVA</h2>
<p><img src="images/13.PNG" width="713" /><img src="images/14.PNG" width="723" /></p>
<div id="way-anova" class="section level3">
<h3><span class="header-section-number">6.6.1</span> 1-way ANOVA</h3>
<pre class="r"><code>boxplot(mtcars$mpg~factor(mtcars$gear),xlab=&#39;gear&#39;,ylab=&#39;mpg&#39;)</code></pre>
<p><img src="index_files/figure-html/unnamed-chunk-49-1.png" /><!-- --></p>
<pre class="r"><code># p-value less than 0.05 -&gt; reject H0, therefore the mean of mpg changes with different types of gears
oneway.test(mtcars$mpg~factor(mtcars$gear))</code></pre>
<pre><code>## 
##  One-way analysis of means (not assuming equal variances)
## 
## data:  mtcars$mpg and factor(mtcars$gear)
## F = 11.285, num df = 2.0000, denom df = 9.5083, p-value = 0.003085</code></pre>
<pre class="r"><code># Same as above but with variance metrics
mtcars.aov = aov(mtcars$mpg ~ as.factor(mtcars$gear))
summary(mtcars.aov)</code></pre>
<pre><code>##                        Df Sum Sq Mean Sq F value   Pr(&gt;F)    
## as.factor(mtcars$gear)  2  483.2  241.62    10.9 0.000295 ***
## Residuals              29  642.8   22.17                     
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
<pre class="r"><code># Tukey multiple comparison of means
mtcars_posthoc =TukeyHSD(mtcars.aov)
mtcars_posthoc</code></pre>
<pre><code>##   Tukey multiple comparisons of means
##     95% family-wise confidence level
## 
## Fit: aov(formula = mtcars$mpg ~ as.factor(mtcars$gear))
## 
## $`as.factor(mtcars$gear)`
##          diff        lwr       upr     p adj
## 4-3  8.426667  3.9234704 12.929863 0.0002088
## 5-3  5.273333 -0.7309284 11.277595 0.0937176
## 5-4 -3.153333 -9.3423846  3.035718 0.4295874</code></pre>
<pre class="r"><code># Plot shows that the differences between cars having 3 or 4 gears are the greatest because the confidence interval is furthest to the right of the plot. 
plot(mtcars_posthoc)</code></pre>
<p><img src="index_files/figure-html/unnamed-chunk-49-2.png" /><!-- --></p>
</div>
<div id="way-anova-1" class="section level3">
<h3><span class="header-section-number">6.6.2</span> 2-way ANOVA</h3>
<p>This is the extension of a 1-way ANOVA since the analysis covers more than 2 categorical variables rather than 1.</p>
<pre class="r"><code># PLOTTING
par(mfrow=c(1,2))

# Clearly there seems to be differences between gear, transmissions and mpg
boxplot(mtcars$mpg~mtcars$gear,subset=(mtcars$am==0),xlab=&#39;gear&#39;,
        ylab = &quot;mpg&quot;,main=&#39;automatic&#39;)

boxplot(mtcars$mpg~mtcars$gear,subset=(mtcars$am==1),xlab=&#39;gear&#39;,
        ylab = &quot;mpg&quot;, main=&#39;manual&#39;)</code></pre>
<p><img src="index_files/figure-html/unnamed-chunk-50-1.png" /><!-- --></p>
<pre class="r"><code># With this interaction plot, we can caracterize the relationship between variables. The resulting plot shows that the number of gears does have an effect on the mean of the mpg, but does not show a positive relationship 
interaction.plot(mtcars$gear, mtcars$am, mtcars$mpg, type=&quot;b&quot;,
                 col=c(1:3),leg.bty=&quot;o&quot;, leg.bg=&quot;beige&quot;, lwd=2, pch=c(18,24,22),
                 xlab=&quot;Number of Gears&quot;, ylab=&quot;Mean Miles Per Gallon&quot;,
                 main=&quot;Interaction Plot&quot;)

# 2-ways anova on MPG with combination of the other factors -&gt; output shows that the p-value of the gear is lower than 0.05, therefore cars with different number of gears are more likely to have different means of mpg
mpg_anova2 = aov(mtcars$mpg~factor(mtcars$gear)*factor(mtcars$am))
summary(mpg_anova2)</code></pre>
<pre><code>##                     Df Sum Sq Mean Sq F value   Pr(&gt;F)    
## factor(mtcars$gear)  2  483.2  241.62  11.869 0.000185 ***
## factor(mtcars$am)    1   72.8   72.80   3.576 0.069001 .  
## Residuals           28  570.0   20.36                     
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
<pre class="r"><code>TukeyHSD(mpg_anova2)</code></pre>
<pre><code>##   Tukey multiple comparisons of means
##     95% family-wise confidence level
## 
## Fit: aov(formula = mtcars$mpg ~ factor(mtcars$gear) * factor(mtcars$am))
## 
## $`factor(mtcars$gear)`
##          diff        lwr       upr     p adj
## 4-3  8.426667  4.1028616 12.750472 0.0001301
## 5-3  5.273333 -0.4917401 11.038407 0.0779791
## 5-4 -3.153333 -9.0958350  2.789168 0.3999532
## 
## $`factor(mtcars$am)`
##         diff       lwr     upr     p adj
## 1-0 1.805128 -1.521483 5.13174 0.2757926</code></pre>
<pre class="r"><code>par(mfrow=c(1,2))</code></pre>
<p><img src="index_files/figure-html/unnamed-chunk-50-2.png" /><!-- --></p>
<pre class="r"><code>plot(TukeyHSD(mpg_anova2))</code></pre>
<p><img src="index_files/figure-html/unnamed-chunk-50-3.png" /><!-- --></p>
</div>
</div>
</div>




</div>

<script>

// add bootstrap table styles to pandoc tables
function bootstrapStylePandocTables() {
  $('tr.header').parent('thead').parent('table').addClass('table table-condensed');
}
$(document).ready(function () {
  bootstrapStylePandocTables();
});


</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>

</body>
</html>
